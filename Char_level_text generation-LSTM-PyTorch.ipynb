{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFiles(path): return glob.glob(path) #Takes regex and returns all the paths that follow the regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in findFiles('dinos.txt'):\n",
    "    lines = readLines(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 256,layers = 2, output_size = 59, drop_prob = 0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hc):\n",
    "#         print(input.shape, hc[0].shape, hc[1].shape)\n",
    "        x , (h,c) = self.lstm(input, hc)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size()[0]*x.size()[1], self.hidden_size)\n",
    "        x = self.fc(x)\n",
    "        output = self.softmax(x)\n",
    "        return output, (h,c)\n",
    "\n",
    "    def initHidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.layers, n_seqs, self.hidden_size).zero_(),\n",
    "                weight.new(self.layers, n_seqs, self.hidden_size).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    line = randomChoice(lines)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(1, len(line), n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[0][li][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make category, input, and target tensors from a random category, line pair\n",
    "def randomTrainingExample():\n",
    "    line = randomTrainingPair()\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(input_line_tensor, target_line_tensor):\n",
    "#    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden(1)\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    output, hidden = rnn(input_line_tensor, hidden)\n",
    "    l = criterion(output, target_line_tensor)\n",
    "    loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (lstm): LSTM(59, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=59, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "2m 32s (5000 5%) 3.9103\n",
      "5m 7s (10000 10%) 3.6634\n",
      "7m 52s (15000 15%) 3.1716\n",
      "10m 38s (20000 20%) 3.1979\n",
      "13m 22s (25000 25%) 2.8389\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, 128,2,n_letters)\n",
    "print(rnn)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cd678ff048>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3331, -4.3527, -3.6021, -3.9165, -3.1244, -4.8411, -3.7698, -3.5238,\n",
      "         -3.0175, -4.7690, -4.3177, -3.3973, -3.9259, -3.0907, -2.6720, -3.6705,\n",
      "         -4.9492, -2.9956, -3.3165, -3.3394, -3.2776, -4.3580, -4.8246, -4.5160,\n",
      "         -3.9347, -4.7205, -4.9697, -4.9229, -4.9599, -4.8702, -4.9438, -4.9392,\n",
      "         -4.9479, -4.9436, -5.0075, -4.8970, -4.9054, -4.9668, -4.9482, -4.9511,\n",
      "         -5.0068, -4.9353, -4.9682, -4.9077, -4.9307, -4.9023, -4.9559, -4.9009,\n",
      "         -4.9936, -4.8887, -4.9496, -4.8813, -4.9433, -4.9227, -5.0290, -4.8715,\n",
      "         -4.9033, -4.9923, -3.9906]])\n",
      "tensor([[-2.3331]]) tensor([[0]])\n",
      "tensor([[-1.9907, -4.7272, -3.5819, -3.9339, -2.9043, -5.6572, -3.7709, -3.5236,\n",
      "         -2.7812, -5.4100, -4.7063, -3.3059, -3.9834, -2.8286, -2.3287, -3.6075,\n",
      "         -5.6822, -2.7046, -2.9825, -3.1477, -3.0129, -4.7248, -5.4472, -4.8902,\n",
      "         -4.0431, -5.3960, -5.7929, -5.7090, -5.7360, -5.6733, -5.7416, -5.8259,\n",
      "         -5.6375, -5.6893, -5.8028, -5.7790, -5.7087, -5.6515, -5.7539, -5.7538,\n",
      "         -5.7596, -5.6337, -5.7662, -5.6349, -5.7841, -5.7092, -5.7384, -5.6236,\n",
      "         -5.7272, -5.7289, -5.7968, -5.7044, -5.7250, -5.7542, -5.8308, -5.6617,\n",
      "         -5.6601, -5.8630, -3.8169]])\n",
      "tensor([[-1.9907]]) tensor([[0]])\n",
      "tensor([[-1.8707, -5.1976, -3.5604, -3.9746, -2.9792, -6.2875, -3.8824, -3.5255,\n",
      "         -2.8592, -6.1022, -5.0595, -3.2668, -4.1561, -2.7677, -2.1081, -3.6046,\n",
      "         -6.3912, -2.5248, -2.7455, -3.0577, -2.8384, -5.2270, -6.0244, -5.3342,\n",
      "         -4.1572, -5.9819, -6.5056, -6.5517, -6.5195, -6.4060, -6.4135, -6.5487,\n",
      "         -6.4309, -6.4275, -6.5597, -6.4406, -6.3534, -6.4908, -6.4661, -6.4816,\n",
      "         -6.4996, -6.2575, -6.5256, -6.3572, -6.4747, -6.4298, -6.3953, -6.3672,\n",
      "         -6.4377, -6.3824, -6.4405, -6.4149, -6.4627, -6.5244, -6.5467, -6.2798,\n",
      "         -6.3627, -6.5370, -3.6431]])\n",
      "tensor([[-1.8707]]) tensor([[0]])\n",
      "tensor([[-1.7955, -5.5046, -3.6274, -4.1697, -3.0325, -6.9717, -4.0244, -3.6111,\n",
      "         -2.7171, -6.5599, -5.4170, -3.5170, -4.3546, -2.7403, -2.0323, -3.7538,\n",
      "         -6.9985, -2.4947, -2.5495, -3.1126, -2.6444, -5.3813, -6.5123, -5.5567,\n",
      "         -4.2447, -6.5934, -7.2015, -6.9829, -6.9797, -6.9754, -7.0695, -7.2119,\n",
      "         -6.8184, -7.0216, -7.1903, -7.0037, -6.9901, -6.8711, -7.0676, -7.0147,\n",
      "         -7.1622, -6.8450, -7.0811, -6.9228, -7.1388, -7.0829, -7.1619, -6.7549,\n",
      "         -6.9854, -6.9704, -7.1986, -7.1126, -7.0548, -7.1070, -7.1044, -6.7923,\n",
      "         -7.0214, -7.2198, -3.5339]])\n",
      "tensor([[-1.7955]]) tensor([[0]])\n",
      "tensor([[-1.7863, -6.1257, -3.8304, -4.2393, -3.0023, -7.6843, -4.2047, -3.7323,\n",
      "         -2.9016, -7.3902, -5.8359, -3.4901, -4.5653, -2.6838, -2.0341, -3.8802,\n",
      "         -7.8200, -2.3931, -2.3556, -3.0368, -2.4752, -6.0919, -7.2517, -6.1090,\n",
      "         -4.5186, -7.4276, -8.1132, -8.0671, -7.8703, -7.7703, -7.8630, -8.1260,\n",
      "         -7.8030, -7.7913, -8.1278, -7.9544, -7.9020, -7.9066, -7.8824, -7.8429,\n",
      "         -7.9281, -7.7147, -8.0605, -7.8148, -8.0388, -7.8245, -7.8798, -7.6808,\n",
      "         -7.8994, -7.8342, -8.0135, -7.9843, -8.0044, -8.0217, -8.0557, -7.7192,\n",
      "         -7.7891, -8.0278, -3.2490]])\n",
      "tensor([[-1.7863]]) tensor([[0]])\n",
      "tensor([[-1.8667, -6.2920, -3.8845, -4.2150, -3.1992, -8.0097, -4.2309, -3.7994,\n",
      "         -3.0366, -7.5972, -6.0047, -3.6655, -4.6473, -2.7515, -2.1722, -3.8510,\n",
      "         -8.2835, -2.3281, -2.1468, -2.9884, -2.2687, -6.1802, -7.6534, -6.3252,\n",
      "         -4.6886, -7.7620, -8.4593, -8.3672, -8.3214, -8.2494, -8.1381, -8.4454,\n",
      "         -8.0131, -8.1178, -8.5164, -8.4602, -8.3668, -8.2004, -8.3507, -8.2558,\n",
      "         -8.2504, -8.1446, -8.4350, -8.1624, -8.3794, -8.1567, -8.2471, -7.9498,\n",
      "         -8.3516, -8.2221, -8.3758, -8.3347, -8.2722, -8.3431, -8.2352, -8.0602,\n",
      "         -8.2518, -8.5312, -2.9109]])\n",
      "tensor([[-1.8667]]) tensor([[0]])\n",
      "tensor([[-1.9154, -6.2103, -3.7608, -4.2155, -3.1484, -7.9117, -4.3582, -3.8053,\n",
      "         -3.1339, -7.6486, -6.1626, -3.6827, -4.6419, -2.8443, -2.4053, -3.8219,\n",
      "         -8.1762, -2.4037, -2.1791, -3.0921, -2.0149, -6.3020, -7.7743, -6.3780,\n",
      "         -4.6401, -7.9425, -8.6103, -8.4048, -8.2095, -8.2858, -8.4541, -8.4718,\n",
      "         -8.1268, -8.4570, -8.4757, -8.4915, -8.4370, -8.2748, -8.3917, -8.2251,\n",
      "         -8.4009, -8.3674, -8.6657, -8.1288, -8.4367, -8.1599, -8.3869, -8.2751,\n",
      "         -8.4332, -8.4365, -8.5916, -8.5142, -8.3358, -8.4368, -8.5340, -8.2345,\n",
      "         -8.3070, -8.3419, -2.5355]])\n",
      "tensor([[-1.9154]]) tensor([[0]])\n",
      "tensor([[-2.1131, -6.5197, -3.9465, -4.4983, -3.4137, -8.2308, -4.4824, -3.8549,\n",
      "         -3.4190, -7.7466, -6.3836, -3.8391, -4.7472, -2.9806, -2.5641, -3.9787,\n",
      "         -8.6076, -2.3642, -1.8471, -3.1832, -1.8409, -6.4945, -8.0296, -6.6609,\n",
      "         -4.8169, -8.0188, -8.7379, -8.7612, -8.6991, -8.7322, -8.6914, -8.9095,\n",
      "         -8.3754, -8.5902, -8.7790, -8.7050, -8.7627, -8.4603, -8.6843, -8.6425,\n",
      "         -8.6146, -8.4589, -8.7843, -8.4092, -8.6611, -8.5387, -8.6890, -8.2697,\n",
      "         -8.7559, -8.6229, -8.7792, -8.9156, -8.6973, -8.8510, -8.6939, -8.3473,\n",
      "         -8.6724, -8.8154, -2.2942]])\n",
      "tensor([[-1.8409]]) tensor([[20]])\n",
      "tensor([[-2.2518, -6.9767, -4.2082, -4.5119, -3.6670, -8.9109, -4.6368, -4.2030,\n",
      "         -3.3984, -8.4428, -6.7461, -3.9696, -5.0904, -3.1471, -2.4710, -3.9266,\n",
      "         -9.0515, -2.3939, -1.7073, -3.4210, -1.8896, -7.0050, -8.4574, -7.2021,\n",
      "         -4.9474, -8.6825, -9.5018, -9.1335, -9.2363, -9.1028, -9.2961, -9.6266,\n",
      "         -8.9821, -9.0627, -9.5399, -9.3119, -9.4126, -9.2543, -9.2772, -9.1662,\n",
      "         -9.2560, -8.9064, -9.4016, -9.0413, -9.1053, -9.1344, -9.2316, -8.9693,\n",
      "         -8.9909, -9.2826, -9.3289, -9.2701, -9.3546, -9.4275, -9.2769, -9.1100,\n",
      "         -9.3772, -9.2616, -1.9535]])\n",
      "tensor([[-1.7073]]) tensor([[18]])\n",
      "tensor([[ -2.5235,  -7.2949,  -4.4597,  -4.7163,  -3.8084,  -9.0816,  -4.7527,\n",
      "          -4.2878,  -3.6265,  -8.8047,  -6.9988,  -4.2177,  -5.3924,  -3.1861,\n",
      "          -2.8527,  -4.1685,  -9.4201,  -2.3763,  -1.6121,  -3.4939,  -1.7915,\n",
      "          -7.1272,  -8.7226,  -7.2841,  -5.3929,  -9.1407,  -9.8728,  -9.6125,\n",
      "          -9.4320,  -9.6501,  -9.6407,  -9.9445,  -9.4917,  -9.4451, -10.0888,\n",
      "          -9.6445,  -9.5979,  -9.8505,  -9.5729,  -9.5831,  -9.6217,  -9.4247,\n",
      "          -9.8199,  -9.5266,  -9.6973,  -9.4001,  -9.4407,  -9.3390,  -9.6552,\n",
      "          -9.6364,  -9.7399,  -9.8401,  -9.5425,  -9.8279,  -9.7717,  -9.3943,\n",
      "          -9.8557,  -9.6266,  -1.6370]])\n",
      "tensor([[-1.6121]]) tensor([[18]])\n",
      "tensor([[-2.7427, -7.4247, -4.5759, -4.6057, -3.8903, -9.2618, -4.8337, -4.4136,\n",
      "         -3.6302, -8.5803, -7.0695, -4.3154, -5.4044, -3.3157, -2.9038, -4.0691,\n",
      "         -9.3554, -2.3114, -1.5299, -3.6526, -1.8460, -7.2416, -8.6459, -7.0202,\n",
      "         -5.2686, -8.7820, -9.7604, -9.5642, -9.5835, -9.6108, -9.5431, -9.9727,\n",
      "         -9.5133, -9.2923, -9.8882, -9.7974, -9.3712, -9.6270, -9.6396, -9.3426,\n",
      "         -9.3712, -9.2181, -9.6427, -9.2973, -9.5792, -9.1841, -9.2952, -9.3248,\n",
      "         -9.5315, -9.5736, -9.7250, -9.5705, -9.5608, -9.6347, -9.6686, -9.3991,\n",
      "         -9.6918, -9.4338, -1.5536]])\n",
      "tensor([[-1.5299]]) tensor([[18]])\n",
      "tensor([[ -2.7529,  -7.6155,  -4.6992,  -4.7231,  -4.0671,  -9.4849,  -5.0145,\n",
      "          -4.4973,  -4.1182,  -9.0121,  -7.2120,  -4.4161,  -5.6625,  -3.4971,\n",
      "          -3.1414,  -4.2012,  -9.6137,  -2.2976,  -1.6071,  -3.7260,  -1.6737,\n",
      "          -7.3315,  -8.8793,  -7.5356,  -5.4717,  -9.0033, -10.1059,  -9.9074,\n",
      "          -9.6253,  -9.7977,  -9.8027, -10.2550,  -9.6372,  -9.7516,  -9.9882,\n",
      "          -9.7308,  -9.8764,  -9.8898,  -9.7986,  -9.8997,  -9.7897,  -9.7405,\n",
      "         -10.0457,  -9.8351,  -9.7519,  -9.5005,  -9.6241,  -9.6399,  -9.7936,\n",
      "          -9.7868,  -9.6981, -10.0304,  -9.8527,  -9.9433,  -9.8291,  -9.6611,\n",
      "          -9.9833,  -9.6457,  -1.4209]])\n",
      "tensor([[-1.4209]]) tensor([[58]])\n",
      "Aaaaaaaausss\n",
      "tensor([[-2.3197, -4.3584, -3.6144, -3.9104, -3.1140, -4.8863, -3.7681, -3.5428,\n",
      "         -2.9833, -4.7484, -4.3565, -3.4025, -3.9221, -3.1208, -2.6698, -3.6615,\n",
      "         -4.9587, -2.9864, -3.2862, -3.3430, -3.2272, -4.3609, -4.8170, -4.5139,\n",
      "         -3.9497, -4.7151, -4.9734, -4.9298, -4.9806, -4.9186, -4.9461, -5.0011,\n",
      "         -4.9825, -4.9521, -5.0117, -4.9374, -4.9067, -4.9711, -4.9950, -4.9523,\n",
      "         -5.0313, -4.9747, -4.9805, -4.9198, -4.9652, -4.9336, -4.9692, -4.8627,\n",
      "         -5.0196, -4.9487, -4.9954, -4.9356, -4.9694, -4.9525, -5.0388, -4.8703,\n",
      "         -4.9187, -5.0212, -3.9401]])\n",
      "tensor([[-2.3197]]) tensor([[0]])\n",
      "tensor([[-1.9724, -4.6906, -3.5656, -3.9567, -2.9734, -5.5636, -3.7595, -3.4792,\n",
      "         -2.7644, -5.3517, -4.6441, -3.3454, -4.0085, -2.8866, -2.3257, -3.5951,\n",
      "         -5.5821, -2.7670, -3.0576, -3.1758, -3.0388, -4.6856, -5.3200, -4.8602,\n",
      "         -4.0117, -5.3251, -5.6685, -5.6240, -5.6681, -5.5693, -5.7029, -5.7417,\n",
      "         -5.5842, -5.5928, -5.7333, -5.6217, -5.5780, -5.5308, -5.6098, -5.6547,\n",
      "         -5.7188, -5.6341, -5.6708, -5.5549, -5.6173, -5.6418, -5.7032, -5.5279,\n",
      "         -5.6605, -5.5651, -5.6838, -5.6204, -5.6534, -5.6841, -5.7048, -5.5134,\n",
      "         -5.5877, -5.6999, -3.8675]])\n",
      "tensor([[-1.9724]]) tensor([[0]])\n",
      "tensor([[-1.9536, -5.1369, -3.6120, -3.9535, -2.9729, -6.1685, -3.8462, -3.4535,\n",
      "         -2.8254, -5.9939, -5.0705, -3.3606, -4.1574, -2.7082, -2.1539, -3.6002,\n",
      "         -6.3304, -2.5387, -2.7307, -3.0954, -2.7256, -5.1232, -5.9742, -5.2282,\n",
      "         -4.1176, -6.0133, -6.5857, -6.3531, -6.3951, -6.2846, -6.4262, -6.5091,\n",
      "         -6.3146, -6.3292, -6.5430, -6.4075, -6.3986, -6.3428, -6.3590, -6.3639,\n",
      "         -6.3880, -6.3569, -6.5846, -6.2786, -6.3907, -6.2877, -6.3939, -6.2173,\n",
      "         -6.3483, -6.4451, -6.5006, -6.4741, -6.3814, -6.4960, -6.5179, -6.1951,\n",
      "         -6.3585, -6.5374, -3.5495]])\n",
      "tensor([[-1.9536]]) tensor([[0]])\n",
      "tensor([[-1.9008, -5.4884, -3.5980, -4.1660, -2.9756, -6.5944, -3.9027, -3.4435,\n",
      "         -2.7273, -6.2215, -5.2116, -3.3854, -4.2991, -2.6999, -2.2009, -3.7312,\n",
      "         -6.7864, -2.3670, -2.6777, -3.0857, -2.6332, -5.3530, -6.2974, -5.6697,\n",
      "         -4.2093, -6.3761, -6.8348, -6.9323, -6.8046, -6.7134, -6.8867, -7.0284,\n",
      "         -6.7119, -6.7319, -6.9387, -6.8162, -6.7006, -6.6602, -6.8095, -6.6942,\n",
      "         -6.9014, -6.5842, -6.9896, -6.7708, -6.8524, -6.7587, -6.7835, -6.6283,\n",
      "         -6.8988, -6.5394, -6.9073, -6.9347, -6.8890, -6.9016, -6.7852, -6.6333,\n",
      "         -6.6511, -6.8519, -3.4078]])\n",
      "tensor([[-1.9008]]) tensor([[0]])\n",
      "tensor([[-1.8160, -5.8610, -3.7338, -4.2049, -2.9417, -7.3378, -4.1603, -3.6765,\n",
      "         -2.8904, -7.0746, -5.6885, -3.6142, -4.4249, -2.6903, -2.1798, -3.6302,\n",
      "         -7.5343, -2.4828, -2.3952, -3.0729, -2.3938, -5.9424, -7.0910, -6.0160,\n",
      "         -4.4896, -7.1877, -7.8108, -7.6654, -7.6566, -7.5582, -7.7052, -7.7955,\n",
      "         -7.3152, -7.4804, -7.7435, -7.8080, -7.7841, -7.5255, -7.5528, -7.5731,\n",
      "         -7.7272, -7.3998, -7.8435, -7.4755, -7.6903, -7.5740, -7.6873, -7.4455,\n",
      "         -7.6189, -7.6468, -7.6911, -7.5992, -7.5431, -7.6582, -7.7177, -7.4435,\n",
      "         -7.5025, -7.7445, -3.0207]])\n",
      "tensor([[-1.8160]]) tensor([[0]])\n",
      "tensor([[-1.9687, -6.1372, -4.0161, -4.1236, -3.0332, -7.6466, -4.2980, -3.7839,\n",
      "         -3.0152, -7.3644, -6.0316, -3.5535, -4.5266, -2.7250, -2.1517, -3.5690,\n",
      "         -7.9410, -2.4151, -2.1933, -3.0892, -2.1945, -6.0185, -7.4050, -6.3695,\n",
      "         -4.5005, -7.5772, -8.3484, -8.0526, -7.9572, -8.0091, -8.1292, -8.1972,\n",
      "         -7.9505, -8.0417, -8.1162, -7.9733, -8.1587, -7.9773, -8.2328, -8.0338,\n",
      "         -7.9281, -7.7657, -8.2678, -7.9256, -7.9878, -7.7732, -7.8845, -7.9382,\n",
      "         -8.0082, -8.0728, -8.1277, -8.0737, -8.0037, -8.1325, -8.2759, -7.8023,\n",
      "         -7.7761, -8.1533, -2.9485]])\n",
      "tensor([[-1.9687]]) tensor([[0]])\n",
      "tensor([[-2.0867, -6.4440, -3.8470, -4.2485, -3.1383, -8.2041, -4.3814, -3.9277,\n",
      "         -3.1108, -7.8597, -6.3857, -3.7863, -4.8533, -2.7749, -2.2617, -3.8272,\n",
      "         -8.3530, -2.4036, -2.0798, -3.1848, -1.9626, -6.2882, -7.7520, -6.4125,\n",
      "         -4.8066, -8.0267, -8.7787, -8.6717, -8.3116, -8.4497, -8.5104, -8.8195,\n",
      "         -8.3054, -8.5389, -8.7036, -8.6760, -8.6075, -8.4159, -8.5677, -8.5967,\n",
      "         -8.4838, -8.3397, -8.7529, -8.3369, -8.5075, -8.5367, -8.4593, -8.4287,\n",
      "         -8.4625, -8.5124, -8.5750, -8.6185, -8.6040, -8.5744, -8.8253, -8.3496,\n",
      "         -8.4770, -8.4763, -2.5105]])\n",
      "tensor([[-1.9626]]) tensor([[20]])\n",
      "tensor([[-2.2044, -6.8867, -4.1739, -4.5187, -3.3580, -8.5786, -4.5915, -4.0048,\n",
      "         -3.3453, -8.1428, -6.5370, -4.0798, -5.0477, -2.9166, -2.5216, -3.9469,\n",
      "         -8.7780, -2.3228, -1.8182, -3.2073, -1.8654, -6.5271, -8.0690, -6.7105,\n",
      "         -4.9664, -8.3833, -9.1627, -8.9910, -8.8672, -8.8105, -8.9358, -9.2601,\n",
      "         -8.6681, -8.8582, -9.2076, -9.1306, -8.9250, -8.9216, -9.0053, -8.8701,\n",
      "         -8.7616, -8.7802, -9.3444, -8.7622, -8.9405, -8.7348, -8.8997, -8.8422,\n",
      "         -8.9314, -8.8689, -9.0162, -8.9378, -8.8520, -9.0131, -8.9610, -8.7013,\n",
      "         -8.8572, -8.9019, -2.1657]])\n",
      "tensor([[-1.8182]]) tensor([[18]])\n",
      "tensor([[-2.3800, -6.6786, -4.1384, -4.2571, -3.4233, -8.4534, -4.4325, -3.9940,\n",
      "         -3.3103, -7.7752, -6.2835, -3.7848, -4.9772, -3.0963, -2.5908, -3.9633,\n",
      "         -8.5229, -2.2023, -1.8448, -3.2247, -2.0236, -6.5253, -7.9175, -6.5240,\n",
      "         -4.9282, -8.2367, -8.8267, -8.6180, -8.6681, -8.4738, -8.7123, -8.8222,\n",
      "         -8.4524, -8.5394, -8.9700, -8.9425, -8.7164, -8.6742, -8.7575, -8.4778,\n",
      "         -8.5596, -8.5083, -8.8500, -8.4411, -8.7467, -8.0328, -8.3638, -8.3389,\n",
      "         -8.6682, -8.7343, -8.9653, -8.6955, -8.7376, -8.6880, -8.7019, -8.4685,\n",
      "         -8.5186, -8.7301, -1.9104]])\n",
      "tensor([[-1.8448]]) tensor([[18]])\n",
      "tensor([[-2.6775, -7.2471, -4.4509, -4.4809, -3.8565, -8.8938, -4.6672, -4.4119,\n",
      "         -3.8077, -8.4857, -6.7156, -4.2876, -5.3295, -3.1983, -2.9828, -4.0889,\n",
      "         -9.1373, -2.2781, -1.6711, -3.4879, -1.7445, -7.0387, -8.5726, -6.9818,\n",
      "         -5.3148, -8.7658, -9.5335, -9.4254, -9.3449, -9.3064, -9.1868, -9.5475,\n",
      "         -9.0957, -9.0797, -9.5030, -9.4535, -9.4567, -9.3357, -9.4560, -9.3520,\n",
      "         -9.2325, -9.4087, -9.6004, -9.2477, -9.2858, -9.0558, -9.2544, -9.0546,\n",
      "         -9.2414, -9.5017, -9.3832, -9.3113, -9.3006, -9.3521, -9.2162, -9.1584,\n",
      "         -9.4013, -9.3529, -1.5682]])\n",
      "tensor([[-1.5682]]) tensor([[58]])\n",
      "Baaaaaauss\n",
      "tensor([[-2.3419, -4.3841, -3.5851, -3.9160, -3.1266, -4.8768, -3.7840, -3.5321,\n",
      "         -2.9894, -4.7326, -4.3903, -3.4169, -3.9054, -3.0959, -2.6713, -3.6366,\n",
      "         -4.9815, -2.9871, -3.2599, -3.3546, -3.2479, -4.3593, -4.8070, -4.4777,\n",
      "         -3.9464, -4.7280, -4.9774, -4.9422, -4.9886, -4.9417, -4.9414, -4.9733,\n",
      "         -4.9688, -4.9410, -5.0247, -4.9449, -4.8980, -4.9833, -4.9748, -4.9870,\n",
      "         -5.0208, -4.9506, -4.9786, -4.9503, -4.9438, -4.9240, -4.9650, -4.8809,\n",
      "         -4.9835, -4.9309, -5.0009, -4.9309, -4.9524, -4.9401, -5.0155, -4.8854,\n",
      "         -4.9014, -5.0155, -3.9069]])\n",
      "tensor([[-2.3419]]) tensor([[0]])\n",
      "tensor([[-2.0050, -4.7177, -3.5726, -3.9017, -2.9280, -5.5474, -3.7896, -3.5027,\n",
      "         -2.8332, -5.3307, -4.6813, -3.3898, -4.0403, -2.8506, -2.2729, -3.5794,\n",
      "         -5.6652, -2.7202, -3.0018, -3.1381, -3.0032, -4.7063, -5.3991, -4.9017,\n",
      "         -4.0403, -5.3431, -5.7838, -5.6521, -5.6585, -5.6085, -5.6825, -5.7531,\n",
      "         -5.6345, -5.6322, -5.7826, -5.7049, -5.6180, -5.6128, -5.6921, -5.6691,\n",
      "         -5.7002, -5.5943, -5.7318, -5.6108, -5.6564, -5.6731, -5.6809, -5.5715,\n",
      "         -5.7224, -5.6773, -5.7666, -5.6832, -5.7372, -5.7133, -5.8065, -5.6086,\n",
      "         -5.6955, -5.8118, -3.8738]])\n",
      "tensor([[-2.0050]]) tensor([[0]])\n",
      "tensor([[-1.9157, -5.1290, -3.5592, -4.0442, -2.9147, -6.2873, -3.8166, -3.5459,\n",
      "         -2.7393, -5.9559, -4.9697, -3.3281, -4.0864, -2.7342, -2.1675, -3.5432,\n",
      "         -6.2555, -2.5439, -2.8140, -3.0748, -2.8059, -5.1050, -5.9495, -5.1667,\n",
      "         -4.1906, -5.9843, -6.5068, -6.4101, -6.3480, -6.3886, -6.3608, -6.4833,\n",
      "         -6.3565, -6.3599, -6.5995, -6.4325, -6.3592, -6.3152, -6.4392, -6.3789,\n",
      "         -6.4084, -6.2913, -6.4724, -6.2667, -6.4607, -6.3538, -6.4482, -6.2172,\n",
      "         -6.4607, -6.2779, -6.5017, -6.4116, -6.3653, -6.4800, -6.5497, -6.2503,\n",
      "         -6.2816, -6.5243, -3.6418]])\n",
      "tensor([[-1.9157]]) tensor([[0]])\n",
      "tensor([[-1.7953, -5.5762, -3.7283, -4.1638, -2.9517, -6.9100, -4.0300, -3.5323,\n",
      "         -2.8721, -6.6906, -5.4444, -3.3882, -4.4465, -2.6655, -2.0790, -3.7133,\n",
      "         -7.0627, -2.4014, -2.6480, -2.9850, -2.6760, -5.5585, -6.6117, -5.7370,\n",
      "         -4.3821, -6.6844, -7.3013, -7.2412, -7.1890, -7.1632, -7.2649, -7.3025,\n",
      "         -7.0037, -7.1328, -7.3071, -7.2593, -7.1873, -7.0979, -7.0902, -7.1432,\n",
      "         -7.2569, -7.0077, -7.2739, -7.0590, -7.1877, -7.0704, -7.1574, -6.9669,\n",
      "         -7.1579, -7.0926, -7.3629, -7.2055, -7.2151, -7.2251, -7.2582, -6.9415,\n",
      "         -7.0456, -7.3653, -3.3479]])\n",
      "tensor([[-1.7953]]) tensor([[0]])\n",
      "tensor([[-1.8526, -5.9222, -3.7955, -4.1612, -2.9949, -7.4519, -4.1882, -3.7822,\n",
      "         -2.8831, -7.1343, -5.7757, -3.5153, -4.5553, -2.6176, -2.0597, -3.7525,\n",
      "         -7.6033, -2.3249, -2.4188, -3.1034, -2.4138, -5.7974, -7.1736, -6.0647,\n",
      "         -4.5183, -7.2255, -7.9998, -7.7458, -7.7237, -7.7263, -7.7447, -7.9122,\n",
      "         -7.6246, -7.6799, -7.8907, -7.8789, -7.8173, -7.6032, -7.8203, -7.8024,\n",
      "         -7.7426, -7.6745, -7.9394, -7.5548, -7.8840, -7.6578, -7.7228, -7.5996,\n",
      "         -7.7266, -7.6794, -7.8954, -7.8309, -7.8082, -7.8594, -7.7676, -7.6273,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -7.6402, -7.7901, -3.3058]])\n",
      "tensor([[-1.8526]]) tensor([[0]])\n",
      "tensor([[-1.8165, -6.3769, -3.9732, -4.3937, -3.1372, -7.9652, -4.2064, -3.7321,\n",
      "         -3.0719, -7.5754, -6.0421, -3.7012, -4.5858, -2.8151, -2.1193, -3.8340,\n",
      "         -8.1130, -2.3175, -2.1267, -3.0637, -2.2678, -6.3103, -7.6421, -6.3226,\n",
      "         -4.7126, -7.7096, -8.3894, -8.3608, -8.2405, -8.2168, -8.2562, -8.5345,\n",
      "         -8.1341, -8.2368, -8.4974, -8.3592, -8.2790, -8.1696, -8.3312, -8.2049,\n",
      "         -8.2713, -8.0177, -8.3379, -8.0650, -8.3717, -8.2081, -8.2629, -7.9823,\n",
      "         -8.2685, -8.2203, -8.3592, -8.4710, -8.3176, -8.4096, -8.3561, -8.0502,\n",
      "         -8.2629, -8.5463, -3.0750]])\n",
      "tensor([[-1.8165]]) tensor([[0]])\n",
      "tensor([[-1.9740, -6.6060, -4.0949, -4.4812, -3.4021, -8.4692, -4.4070, -3.8984,\n",
      "         -3.1824, -8.0314, -6.3812, -3.7823, -4.9522, -2.8415, -2.2538, -3.9498,\n",
      "         -8.6708, -2.2337, -2.0663, -3.1421, -2.0075, -6.5571, -8.0194, -6.6708,\n",
      "         -4.7749, -8.1421, -8.9182, -8.8569, -8.6860, -8.5127, -8.8523, -9.0365,\n",
      "         -8.6326, -8.6721, -8.9730, -8.8336, -8.8254, -8.6763, -8.6453, -8.7653,\n",
      "         -8.7835, -8.5859, -9.0048, -8.5708, -8.8105, -8.6648, -8.6896, -8.5542,\n",
      "         -8.6988, -8.6839, -8.8075, -8.8730, -8.8717, -8.8737, -8.8316, -8.5682,\n",
      "         -8.6514, -8.7873, -2.5065]])\n",
      "tensor([[-1.9740]]) tensor([[0]])\n",
      "tensor([[-2.2030, -6.4432, -3.9937, -4.2589, -3.4420, -8.1725, -4.3984, -4.0421,\n",
      "         -3.1262, -7.7523, -6.3578, -3.8477, -4.7991, -2.8768, -2.4648, -4.0339,\n",
      "         -8.2740, -2.2367, -1.9125, -3.1550, -1.9235, -6.3813, -7.8917, -6.4514,\n",
      "         -4.6929, -8.1343, -8.6688, -8.6508, -8.4846, -8.3816, -8.6160, -8.7938,\n",
      "         -8.3181, -8.3506, -8.8713, -8.6328, -8.6583, -8.3038, -8.6401, -8.4888,\n",
      "         -8.5083, -8.3271, -8.6992, -8.2208, -8.7030, -8.4107, -8.3899, -8.4547,\n",
      "         -8.5062, -8.4975, -8.7007, -8.5572, -8.4376, -8.5214, -8.4036, -8.4198,\n",
      "         -8.3567, -8.4378, -2.3492]])\n",
      "tensor([[-1.9125]]) tensor([[18]])\n",
      "tensor([[-2.3343, -7.0942, -4.3096, -4.4773, -3.5214, -8.8876, -4.6601, -4.1587,\n",
      "         -3.5205, -8.4841, -6.7961, -4.0763, -5.1221, -3.1361, -2.7779, -3.9361,\n",
      "         -9.1658, -2.2388, -1.7368, -3.3991, -1.8130, -7.0617, -8.5370, -7.1325,\n",
      "         -5.1608, -8.7692, -9.5442, -9.4650, -9.1627, -9.3218, -9.3460, -9.7130,\n",
      "         -9.0787, -9.2566, -9.5210, -9.4211, -9.4106, -9.3844, -9.4019, -9.2125,\n",
      "         -9.3442, -9.1096, -9.5788, -9.1934, -9.4501, -9.1442, -9.2791, -9.2627,\n",
      "         -9.4211, -9.4475, -9.4827, -9.4668, -9.5273, -9.3824, -9.5754, -9.1603,\n",
      "         -9.3541, -9.3091, -1.8717]])\n",
      "tensor([[-1.7368]]) tensor([[18]])\n",
      "tensor([[-2.2482, -6.9572, -4.2072, -4.7046, -3.4964, -8.9837, -4.7255, -4.2238,\n",
      "         -3.6436, -8.5295, -6.9433, -3.9873, -5.0327, -3.1549, -2.7372, -3.9940,\n",
      "         -8.9890, -2.3059, -1.7255, -3.4153, -1.7805, -7.0479, -8.4723, -7.1166,\n",
      "         -5.2558, -8.6309, -9.4818, -9.4405, -9.3446, -9.5411, -9.3972, -9.5471,\n",
      "         -9.1497, -9.1978, -9.6727, -9.5013, -9.5014, -9.3594, -9.3604, -9.2329,\n",
      "         -9.3774, -9.1285, -9.4768, -9.2000, -9.4833, -9.1598, -9.2749, -9.1502,\n",
      "         -9.3093, -9.4622, -9.4490, -9.3193, -9.2446, -9.3996, -9.3085, -9.2202,\n",
      "         -9.3279, -9.4268, -1.9106]])\n",
      "tensor([[-1.7255]]) tensor([[18]])\n",
      "tensor([[-2.6888, -7.2375, -4.4820, -4.6820, -3.9136, -9.2107, -4.8644, -4.2593,\n",
      "         -3.8697, -8.7676, -6.9160, -4.0660, -5.3725, -3.3597, -3.1801, -4.1568,\n",
      "         -9.3152, -2.3559, -1.6490, -3.5805, -1.6629, -7.1756, -8.6442, -7.1160,\n",
      "         -5.1495, -9.1403, -9.7611, -9.8355, -9.5089, -9.4223, -9.6086, -9.8358,\n",
      "         -9.3642, -9.2791, -9.8959, -9.5713, -9.7109, -9.6371, -9.5689, -9.5053,\n",
      "         -9.5362, -9.3012, -9.7147, -9.2682, -9.5384, -9.3673, -9.5064, -9.3116,\n",
      "         -9.4824, -9.5811, -9.6151, -9.5707, -9.3614, -9.6002, -9.7131, -9.4046,\n",
      "         -9.4610, -9.5832, -1.5211]])\n",
      "tensor([[-1.5211]]) tensor([[58]])\n",
      "Caaaaaaasss\n"
     ]
    }
   ],
   "source": [
    "max_length = 20\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden(1)\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(input, hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            print(output)\n",
    "            print(topv, topi)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(start_letter))\n",
    "\n",
    "samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaaaaaasu\n",
      "Baaaaaaasuu\n",
      "Caaaaaasusu\n"
     ]
    }
   ],
   "source": [
    "samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('gans': conda)",
   "language": "python",
   "name": "python361064bitganscondae4718ca57fa4475da4d8716e561e0e65"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
